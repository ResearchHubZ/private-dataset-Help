# private-dataset-Help-
The "Help" dataset was constructed using a stratified sampling approach, covering 13 cities throughout the entire year of 2024. The sampled data encompass the demands of individuals from diverse age groups and occupational backgrounds and include all core scenarios related to citizens’ daily life and urban operations. 
We conducted rigorous data cleaning on the sample data, detecting and removing outliers, missing entries, and invalid records. Subsequently, a manual second-pass verification was carried out to ascertain the ground-truth intent underlying each instance. The final dataset comprises 86,627 samples annotated with 600 distinct intent classes.Specifically, the stratified sampling strategy was adopted to mitigate sampling bias in intent recognition benchmarks and to ensure representativeness across demographic, geographic, and scenario dimensions. Geographically, the sampling spans 13 cities, preventing overrepresentation of any single urban environment and ensuring the dataset reflects the diversity of citizen service demands across regions. Temporally, the data collection window covers the entire year of 2024, including statutory holidays (e.g., Spring Festival, National Day), seasonal transitions, and periods of peak urban service demand (e.g., summer flood control, winter heating). This temporal stratification addresses the common issue of insufficient intent representation in short-term datasets, enabling models to learn persistent intent patterns across time. The dataset not only captures heterogeneous user demands across diverse populations but also encompasses all core domains of citizen daily life and urban management, ensuring fine-grained coverage of intents.To guarantee data quality, a rigorous two-stage preprocessing pipeline was implemented. In the first stage, a hybrid approach combining rule-based and statistical methods was applied to handle anomalies. Using the interquartile range (IQR) method and domain-specific rules, 2,137 outlier samples exhibiting significant deviations from normal citizen service query patterns were removed. Records with missing fields were addressed by imputing categorical variables with the mode, and 892 records with critical missing information were excluded. Additionally, 1,563 invalid samples were removed, including duplicates detected via text embedding cosine similarity greater than 0.95, spam, non-service-related conversational content, and incomplete sentences. In the second stage, manual secondary verification was performed. Five annotators, each with over two years of experience in citizen service, reviewed all cleaned samples. Each sample was independently labeled by two annotators to confirm: (1) the semantic validity of the query (i.e., whether the citizen’s service request was clearly expressed); (2) the accuracy of the intent label (i.e., whether the preliminary label assigned during data collection matched the user’s actual intent); and (3) contextual completeness (i.e., whether any additional context provided was sufficient to determine the intent). Disagreements between annotators were resolved through group discussions led by a senior annotator with five years of experience.After this preprocessing and verification procedure, the final Help dataset contains 81,820 valid samples, each annotated with a unique intent label. These labels are organized into a classification system comprising 600 distinct intent classes to support this study.
